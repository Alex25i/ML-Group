{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9: PyTorch\n",
    "\n",
    "List your team members (name and immatriculation number) and indicate whether you are a B.Sc. Data Science or other group in the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Jonas Lammert 3149269\n",
    "\n",
    "Alexander Tiessen 2965198\n",
    "\n",
    "Patrick Schneefuss 2951267\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you wish to present any of the tasks, please tell us here.**\n",
    "We want to present task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage  # Package name: scikit-image, requires installation of package 'Pillow'\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import torch  # Package name: torch (for pip), pytorch (for conda)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_airfoil_dataset():\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    data = np.genfromtxt('airfoil_self_noise.csv')\n",
    "    X, y = data[:, :5], data[:, 5]\n",
    "    y = y.reshape(-1, 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2020)\n",
    "\n",
    "    scaler_X = StandardScaler().fit(X_train)\n",
    "    scaler_y = StandardScaler().fit(y_train)\n",
    "    X_train = scaler_X.transform(X_train)\n",
    "    X_test = scaler_X.transform(X_test)\n",
    "    y_train = scaler_y.transform(y_train)\n",
    "    y_test = scaler_y.transform(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def load_traffic_sign_dataset():\n",
    "    import os\n",
    "    \n",
    "    def load_data(directory):\n",
    "        directories = [d for d in os.listdir(directory)\n",
    "                       if os.path.isdir(os.path.join(directory, d))]\n",
    "        labels = []\n",
    "        images = []\n",
    "        for d in directories:\n",
    "            label_directory = os.path.join(directory, d)\n",
    "            file_names = [os.path.join(label_directory, f)\n",
    "                          for f in os.listdir(label_directory)\n",
    "                          if f.endswith(\".ppm\")]\n",
    "            for f in file_names:\n",
    "                images.append(skimage.io.imread(f))\n",
    "                labels.append(int(d))\n",
    "        images, labels = np.array(images), np.array(labels)\n",
    "        images = np.array([skimage.transform.resize(img, (50, 50)) for img in images])\n",
    "        return images, labels\n",
    "            \n",
    "    X_train, y_train = load_data('BelgiumTSC_Training/Training')\n",
    "    X_test, y_test = load_data('BelgiumTSC_Testing/Testing')\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return dict(X=self.X[idx], y=self.y[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    \n",
    "class FlattenedImageDataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = np.array([img.flatten() for img in X])\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return dict(X=self.X[idx], y=self.y[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Linear Regression with SGD in PyTorch\n",
    "\n",
    "In this first task, you will implement a linear regression model in PyTorch without using the existing [`torch.nn.Linear`](https://pytorch.org/docs/master/generated/torch.nn.Linear.html) module. Instead use basic math operations such as addition and matrix multiplication for the computation of the forward pass. The computation of gradients and performing backpropagation will be automatically handled by PyTorch.\n",
    "\n",
    "Initialize the weights and bias of the linear model using the standard Gaussian distribution similar to Assignment 8 - Task 3. The `bias` parameter selects whether a bias term should be included in the model.\n",
    "\n",
    "*Hint:* To allow training of the network, the weights of the model have to be made trainable. A convenient way to do this is to instantiate the learnable parameters as [`torch.nn.Parameter`](https://pytorch.org/docs/master/generated/torch.nn.parameter.Parameter.html) objects and set them as fields of a [`torch.nn.Module`](https://pytorch.org/docs/master/generated/torch.nn.Module.html) subclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.bias = bias\n",
    "\n",
    "        # Your initialization code comes here.\n",
    "        self.weights = torch.nn.Parameter(torch.randn([self.out_features,self.in_features],requires_grad=True))\n",
    "        if self.bias:\n",
    "            self.b = torch.nn.Parameter(torch.randn(self.out_features,requires_grad=True))\n",
    "        #print(self.weights.size())\n",
    "        #print(self.b.size())\n",
    "       \n",
    "\n",
    "    def forward(self, X):\n",
    "        # The forward pass of the linear regression comes here.\n",
    "        if self.bias:\n",
    "            return torch.mm(X,self.weights.t())  + self.b\n",
    "        else:\n",
    "            return torch.mm(X,self.weights.t())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide you with the necessary code to train and compare your model and the reference implementation of PyTorch. You will have to replicate similar training code for multi-class classification in Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MyLinear\nEpoch 1/25 - Loss: 98.86190700531006\nEpoch 2/25 - Loss: 45.2108154296875\nEpoch 3/25 - Loss: 28.790478587150574\nEpoch 4/25 - Loss: 22.415533185005188\nEpoch 5/25 - Loss: 19.457853615283966\nEpoch 6/25 - Loss: 17.76119166612625\nEpoch 7/25 - Loss: 16.26225608587265\nEpoch 8/25 - Loss: 15.292825639247894\nEpoch 9/25 - Loss: 14.15049034357071\nEpoch 10/25 - Loss: 13.469334363937378\nEpoch 11/25 - Loss: 12.714170396327972\nEpoch 12/25 - Loss: 12.015116751194\n/home/patrick/.local/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\nEpoch 13/25 - Loss: 11.56441655755043\nEpoch 14/25 - Loss: 11.11351364850998\nEpoch 15/25 - Loss: 10.643710434436798\nEpoch 16/25 - Loss: 10.287648677825928\nEpoch 17/25 - Loss: 10.074970096349716\nEpoch 18/25 - Loss: 9.755223572254181\nEpoch 19/25 - Loss: 9.435763955116272\nEpoch 20/25 - Loss: 9.243107676506042\nEpoch 21/25 - Loss: 9.156526386737823\nEpoch 22/25 - Loss: 8.94119855761528\nEpoch 23/25 - Loss: 8.769163876771927\nEpoch 24/25 - Loss: 8.727158516645432\nEpoch 25/25 - Loss: 8.741661489009857\nTest MSE: 0.5072325999625124\n\ntorch.nn.Linear\nEpoch 1/25 - Loss: 19.521960139274597\nEpoch 2/25 - Loss: 14.86082774400711\nEpoch 3/25 - Loss: 12.329993307590485\nEpoch 4/25 - Loss: 10.424086660146713\nEpoch 5/25 - Loss: 9.458246380090714\nEpoch 6/25 - Loss: 8.994089543819427\nEpoch 7/25 - Loss: 8.490573197603226\nEpoch 8/25 - Loss: 8.205416828393936\nEpoch 9/25 - Loss: 8.108640372753143\nEpoch 10/25 - Loss: 8.001619428396225\nEpoch 11/25 - Loss: 7.942179948091507\nEpoch 12/25 - Loss: 7.831445932388306\nEpoch 13/25 - Loss: 7.907446891069412\nEpoch 14/25 - Loss: 7.850898236036301\nEpoch 15/25 - Loss: 7.839123219251633\nEpoch 16/25 - Loss: 7.874013394117355\nEpoch 17/25 - Loss: 7.8703731298446655\nEpoch 18/25 - Loss: 7.839880049228668\nEpoch 19/25 - Loss: 7.790958523750305\nEpoch 20/25 - Loss: 7.883460581302643\nEpoch 21/25 - Loss: 7.762550204992294\nEpoch 22/25 - Loss: 7.792144864797592\nEpoch 23/25 - Loss: 7.68101766705513\nEpoch 24/25 - Loss: 7.792378067970276\nEpoch 25/25 - Loss: 7.814611166715622\nTest MSE: 0.4572752221593901\n\nsklearn.linear_model.LinearRegression\nTest MSE: 0.4558416188054017\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "epochs = 25\n",
    "in_features = 5\n",
    "out_features = 1\n",
    "\n",
    "# Initialize models.\n",
    "my_linear = MyLinear(in_features, out_features)\n",
    "pt_linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "# Load dataset.\n",
    "X_train, X_test, y_train, y_test = load_airfoil_dataset()\n",
    "dataset_train = BasicDataset(X_train, y_train)\n",
    "\n",
    "\n",
    "def train_model(model, dataset, learning_rate, batch_size, epochs): \n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train linear model using SGD on mini-batches.\n",
    "    for epoch in range(epochs):\n",
    "        # DataLoader generates random batches from a given dataset.\n",
    "        data_loader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "         # We want to report the training loss after each epoch\n",
    "        epoch_loss = 0.0 \n",
    "\n",
    "        for batch in data_loader:\n",
    "            # After each iteration of the training step, reset the local gradients stored in the network to zero.\n",
    "            model.zero_grad()\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Compute the forward pass.\n",
    "            # Numpy uses doubles by default but Torch expects floats, since the added accuracy of doubles \n",
    "            # is generally not useful for neural networks.\n",
    "            # We fix this issue by changing the datatype of 'X' and 'y' with the .float method.\n",
    "            yhat = model.forward(batch['X'].float())\n",
    "\n",
    "            # Compute the batch error.\n",
    "            batch_loss = F.mse_loss(yhat, batch['y'].float())\n",
    "            epoch_loss += batch_loss.item()\n",
    "            \n",
    "            # Backpropagate the gradient and adjust the weights.\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss}')\n",
    "\n",
    "        \n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    X_test = torch.from_numpy(X_test).float()    \n",
    "    yhat = model.forward(X_test).detach().numpy()\n",
    "    mse = np.mean(np.power(yhat - y_test, 2))\n",
    "    print('Test MSE:', mse)\n",
    "    \n",
    "    \n",
    "print('MyLinear')\n",
    "train_model(my_linear, dataset_train, learning_rate, batch_size, epochs)\n",
    "evaluate_model(my_linear, X_test, y_test)\n",
    "print()\n",
    "print('torch.nn.Linear')\n",
    "train_model(pt_linear, dataset_train, learning_rate, batch_size, epochs)\n",
    "evaluate_model(pt_linear, X_test, y_test)\n",
    "print()\n",
    "print('sklearn.linear_model.LinearRegression')\n",
    "print('Test MSE:', np.mean(np.power(LinearRegression().fit(X_train, y_train).predict(X_test) - y_test, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Image Classification with FNN\n",
    "\n",
    "In this task, you will implement an FNN for multi-class classification of traffic signs.\n",
    "\n",
    "Download the [training](https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Training.zip) and [test](https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Testing.zip) data. Unpack the zip-files in the same directory as the Jupyter notebook.\n",
    "\n",
    "The shape of each image is `(width=50, height=50, channels=3)` after resizing. The channels represent the color of each pixel.\n",
    "FNN cannot directly operate on images. We therefore have to flatten each image to a vector.\n",
    "We achieve this with the [`numpy.flatten`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flatten.html) method. The class `FlattenedImageDataset` may be used for training of your FNN.\n",
    "\n",
    "Implement a feedforward neural network with multiple layers using either [`nn.Sequential`](https://pytorch.org/docs/master/generated/torch.nn.Sequential.html) class or by subclassing [`nn.Module`](https://pytorch.org/docs/master/generated/torch.nn.Module.html) as shown in Task 1.  Use a combination [`nn.Linear`](https://pytorch.org/docs/master/generated/torch.nn.Linear.html) and activation functions (e.g. [`nn.ReLU`](https://pytorch.org/docs/master/generated/torch.nn.ReLU.html)) to implement the fully connected layers of an FNN. Experiment with different activation functions (ReLU, tanh, ...), different depths, and widths. Use the Adam optimizer ([`optim.Adam`](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam)) for optimization.\n",
    "\n",
    "You should evaluate your model by at least computing the relevant metrics (e.g. F1-score) and looking at a few misclassified samples.\n",
    "\n",
    "*Note:* You may modify the code from Task 1. However, you need to use an appropriate loss function and output layer for your FNN to train your network for multi-class classification. Use your knowledge from the lecture to identify the correct methods in the [PyTorch documentation](https://pytorch.org/docs/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'BelgiumTSC_Training/Training'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8b28d6b2220d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load training and testing data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_traffic_sign_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training samples:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing samples:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Image shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-cd023ed2a73d>\u001b[0m in \u001b[0;36mload_traffic_sign_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BelgiumTSC_Training/Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BelgiumTSC_Testing/Testing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-cd023ed2a73d>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         directories = [d for d in os.listdir(directory)\n\u001b[0m\u001b[1;32m     25\u001b[0m                        if os.path.isdir(os.path.join(directory, d))]\n\u001b[1;32m     26\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BelgiumTSC_Training/Training'"
     ]
    }
   ],
   "source": [
    "# Load training and testing data.\n",
    "X_train, X_test, y_train, y_test = load_traffic_sign_dataset()\n",
    "print('Training samples:', X_train.shape[0])\n",
    "print('Testing samples:', X_test.shape[0])\n",
    "print('Image shape:', X_train[0].shape)\n",
    "print('#Classes:', len(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9c9e6f9a6716>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimg_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# Show sample for each class.\n",
    "class_labels = set(np.unique(y_train))\n",
    "n_classes = len(class_labels)\n",
    "\n",
    "n_cols = 6\n",
    "n_rows = n_classes // n_cols + 1\n",
    "fig, ax = plt.subplots(n_rows, n_cols, figsize=(n_cols*2, n_rows*2))\n",
    "for label in sorted(class_labels):\n",
    "    row = label // n_cols\n",
    "    col = label % n_cols\n",
    "    img_idx = np.argmax(y_train == label)\n",
    "    ax[row, col].imshow(X_train[img_idx])\n",
    "    ax[row, col].set_xticks([])\n",
    "    ax[row, col].set_yticks([])\n",
    "    ax[row, col].set_title(f'Class = {label}')\n",
    "    \n",
    "leftover_subplots = n_cols - (max(class_labels) % n_cols) - 1\n",
    "for i in range(leftover_subplots):\n",
    "    fig.delaxes(ax[-1, -(i+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your model and training here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your evaluation here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Image Classification with CNN\n",
    "\n",
    "*For all students other than B.Sc. Data Science.*\n",
    "\n",
    "In this task, you will implement a convolutional neural network (CNN) for classification of traffic signs.\n",
    "Your model should use [`nn.Conv2d`](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d) layers to compute convolutions, any kind of pooling (e.g. [`nn.MaxPool2d`](https://pytorch.org/docs/stable/nn.html#torch.nn.MaxPool2d)), and a dense output network.\n",
    "For inspiration look at the architecture of AlexNet (presented in the lecture).\n",
    "For simplicity, you may use the `nn.Sequential` class.\n",
    "\n",
    "You should evaluate your model by at least computing the relevant metrics (e.g. F1-score) and looking at a few misclassified samples.\n",
    "\n",
    "*Note:* For the most part, you can reuse your code from Task 2. However, you have to use images in their original format `(128, 128, 3)` instead of the flattened shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your model and training here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your evaluation here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit3ef25bb8881f428191c8d6eb4fa9e1bf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}