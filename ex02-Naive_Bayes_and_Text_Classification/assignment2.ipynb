{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Naive Bayes and Text Classification\n",
    "\n",
    "Only use the already imported library `numpy`. Make sure that the `spamham.txt` dataset is in the same directory as the notebook.\n",
    "\n",
    "List your team members (name and immatriculation number) in the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jonas Lammert 3149269\n",
    "\n",
    "Alexander Tiessen 2965198\n",
    "\n",
    "Patrick Schneefuss 2951267"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages and dataset. Do not modify.\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_spamham_dataset():\n",
    "    import string\n",
    "    \n",
    "    with open('spamham.txt', mode='r', encoding='utf-8') as f:\n",
    "        rows = [l.strip().split('\\t')[:2] for l in f]\n",
    "    \n",
    "    y, X = zip(*rows)\n",
    "    X =[x.translate(str.maketrans('', '', string.punctuation)).lower().split() for x in X]\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "\n",
    "X, y = load_spamham_dataset()\n",
    "\n",
    "print('Sample:')\n",
    "print(f'{y[0]}: {X[0]}')\n",
    "print(f'{y[2]}: {X[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Spam Classification with Naive Bayes\n",
    "\n",
    "Check out the description of the dataset at [https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection).\n",
    "\n",
    "Implement a Naive Bayes classifier with Laplace smoothing to detect whether a text message is spam or ham (not spam).\n",
    "\n",
    "A text message is represented by a list of string tokens as shown above.\n",
    "The classification target is binary and the two possible labels are the strings `'spam'` and `'ham'`.\n",
    "\n",
    "Fill out the methods in `NaiveBayesSpamClassifier` to train (`fit`) and predict (`predict`). Feel free to introduce new fields and methods based on your needs, but the methods `fit` and `predict` are required and their interface should not be changed.\n",
    "\n",
    "Hint: Try to map the text messages to word frequency vectors by counting how often each word occurs in a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here.\n",
    "class NaiveBayesSpamClassifier(object):\n",
    "    def __init__(self):\n",
    "        self.spam_dict = {\"total_count\": 0}\n",
    "        self.ham_dict = {\"total_count\": 0}\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Go over each message an its corresponding label\n",
    "        for message, label in zip(X, y):\n",
    "            for token in message:\n",
    "                if label == \"spam\":\n",
    "                    self.spam_dict[token] = 0 if (token not in self.spam_dict.keys()) else (self.spam_dict[token] + 1)\n",
    "                    self.spam_dict[\"total_count\"] = self.spam_dict[\"total_count\"] + 1\n",
    "                if label == \"ham\":\n",
    "                    self.ham_dict[token] = 0 if (token not in self.ham_dict.keys()) else (self.ham_dict[token] + 1)\n",
    "                    self.ham_dict[\"total_count\"] = self.ham_dict[\"total_count\"] + 1\n",
    "\n",
    "        for token in self.spam_dict.keys():\n",
    "            if token != \"total_count\":\n",
    "                self.spam_dict[token] = (self.spam_dict[token] + 1) / (self.spam_dict[\"total_count\"] + len(self.spam_dict.keys()) -1)\n",
    "\n",
    "        for token in self.ham_dict.keys():\n",
    "            if token != \"total_count\":\n",
    "                self.ham_dict[token] = (self.ham_dict[token] + 1) / (self.ham_dict[\"total_count\"] + len(self.ham_dict.keys()) -1)        \n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "\n",
    "        y_pred = []\n",
    "        \n",
    "        for message in X:\n",
    "                unique_tokens = list(dict.fromkeys(message))\n",
    "                spam_probability = 1/2\n",
    "                ham_probability = 1/2\n",
    "                # TODO: Factor in total count of word in array\n",
    "                for token in unique_tokens:\n",
    "                    if token in self.spam_dict.keys():\n",
    "                        spam_probability = spam_probability**message.count(token) * self.spam_dict[token]\n",
    "                    if token in self.ham_dict.keys():\n",
    "                        ham_probability = ham_probability**message.count(token) * self.ham_dict[token]\n",
    "                \n",
    "                y_pred.append('ham') if np.argmax(np.asarray([spam_probability, ham_probability])) == 0 else y_pred.append('spam')       \n",
    "\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# The following code will evaluate your classifier.\n",
    "class HamClassifier(object):\n",
    "    \"\"\"\n",
    "    This classifier is a primitive baseline, which just predicts the most common class each time.\n",
    "    Naive Bayes should definitely beat this.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y): pass\n",
    "    def predict(self, X): return len(X)*['ham']\n",
    "\n",
    "    \n",
    "def train_evaluate(classifier, X, y):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Apply train-test split.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2020)\n",
    "    # Inititialize and train classifier.\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # Evaluate classifier on test data.\n",
    "    yhat_test = classifier.predict(X_test)\n",
    "    cmatrix = confusion_matrix(y_test, yhat_test, labels=['ham', 'spam'])\n",
    "    \n",
    "    return cmatrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cmatrix, classifier_name):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.matshow(cmatrix, cmap='Greens')\n",
    "    for x in (0, 1):\n",
    "        for y in (0, 1):\n",
    "            ax.text(x, y, cmatrix[y, x])\n",
    "    ax.set_xlabel('predicted label')\n",
    "    ax.set_ylabel('true label')\n",
    "    ax.set_xticklabels(['', 'ham', 'spam'])\n",
    "    ax.set_yticklabels(['', 'ham', 'spam'])\n",
    "    ax.set_title(classifier_name)\n",
    "\n",
    "    \n",
    "    \n",
    "ham_classifier = HamClassifier()\n",
    "your_classifier = NaiveBayesSpamClassifier()\n",
    "ham_cmatrix = train_evaluate(ham_classifier, X, y)\n",
    "your_cmatrix = train_evaluate(your_classifier, X, y)\n",
    "\n",
    "plot_confusion_matrix(ham_cmatrix, 'HamClassifier')\n",
    "plot_confusion_matrix(your_cmatrix, 'NaiveBayesSpamClassifier')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit3ef25bb8881f428191c8d6eb4fa9e1bf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}