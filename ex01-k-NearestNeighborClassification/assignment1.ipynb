{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: k-nearest neighbors\n",
    "\n",
    "Only use the already imported libraries `numpy` and `matplotlib.pyplot` for the assignment. Do not import any other library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages and dataset. Do not modify.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_iris_dataset():\n",
    "    from sklearn import datasets\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    return X, y\n",
    "    \n",
    "X, y = load_iris_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Visualization and Preprocessing\n",
    "\n",
    "1) Explain the content of the dataset in few words. What are the input features? What is the classification target? Check out: [https://en.wikipedia.org/wiki/Iris_flower_data_set](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a analysis of Iris setosa, Iris virginica and Iris versicolor. From each of them 50 samples are taken.\n",
    "There are two features for the length and the width of the sepals and two features for the length and the width of the petals in centimeters.\n",
    "\n",
    "The classification target is distinguishing the species from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compute and print the following statistics about the dataset:\n",
    "  - Number of samples\n",
    "  - Number of samples per class\n",
    "  - Mean and standard deviation for each input feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = len(y)\n",
    "\n",
    "number_of_samples_0 = np.bincount(y)[0]\n",
    "number_of_samples_1 = np.bincount(y)[1]\n",
    "number_of_samples_2 = np.bincount(y)[2]\n",
    "\n",
    "mean = np.mean(X, axis=0)\n",
    "standard_deviation = np.std(X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Visualize the variables Sepal length and Petal length in a scatter plot (Sepal length on the x-axis, petal length on the y-axis). Color each point of the plot according to its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.get_cmap(name=\"Paired\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Split the dataset randomly into training and test data. 70% of data should be used for training and 30% should be used for testing. Implement the function `train_test_split`. Do not modify the interface of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y):\n",
    "    \"\"\"\n",
    "    Returns X_train, X_test, y_train, y_test, \n",
    "        where X_train and X_test are the input features of the training and test set,\n",
    "        and y_train and y_test are the class labels of the training and test set.\n",
    "    \"\"\"\n",
    "    train, test = np.split(np.random.permutation(np.c_[X, y]), [int(len(y) * 0.7)])\n",
    "\n",
    "\n",
    "    return train[:, :-1], test[:, :-1], train[:, -1], test[:, :-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "assert (X_train.shape[0] + X_test.shape[0]) == X.shape[0]\n",
    "assert (y_train.shape[0] + y_test.shape[0]) == y.shape[0]\n",
    "assert X_train.shape[1] == X_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) kNN uses a distance measure to identify close neighbors. If the input features are not of the same scale, the distance is not as meaningful, which can negatively impact classification performance. Perform min-max scaling (i.e. scale the values of the input features in such a way that their range is from 0 to 1) on the training and test data. Remember that you should only use information from the training data to perform the scaling on both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(x_train, x_toscale):\n",
    "    \n",
    "    X_scaled = (x_toscale - x_train.min(axis=0)) / (x_train.max(axis=0) - x_train.min(axis=0))    \n",
    "    return X_scaled  \n",
    "\n",
    "X_test = min_max(X_train, X_test)\n",
    "X_train = min_max(X_train, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: k-nearest neighbors\n",
    "\n",
    "**For B.Sc. Data Science:**  \n",
    "Implement the kNN algorithm with uniform weighting and arbitrary `k`. Fill out the `predict` method of class `KNearestNeighborsClassifier`. \n",
    "\n",
    "Use Euclidean distance to determine the nearest neighbors.\n",
    "You can ignore the optional parameter `distance_metric`, which is provided as a field in the kNN class.\n",
    "\n",
    "**For everyone else:**  \n",
    "Implement the kNN algorithm with distance-based weighting and arbitrary `k`.\n",
    "Fill out the `predict` method of class `KNearestNeighborsClassifier`.\n",
    "\n",
    "The parameter `distance_metric` will either contain the string `uniform` or a function. If the value is `uniform`, the classifier should use the Euclidean distance for determining nearest neighbors and uniform weighting. If the value is a function, the classifier should use the function as distance metric and perform distance-weighted classification. An example distance metric is provided with `euclidean_distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors(object):\n",
    "    def __init__(self, k, distance_metric='uniform'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        This functions saves the training data to be used during the prediction.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Returns a vector of shape (n,) if X has shape (n,d), \n",
    "        where n is the number of samples and d is the number of features.\n",
    "        \"\"\"\n",
    "        y_pred = []\n",
    "               \n",
    "        for sample in X:            \n",
    "            # entry of form [index, distance, label, weight]\n",
    "            distance = []\n",
    "            for i in range(len(self.X)):                \n",
    "                dist = euclidean_distance(self.X[i], sample) if self.distance_metric == 'uniform' else self.distance_metric(self.X[i],sample)                \n",
    "                distance.append([i,dist,int(self.y[i]), 0])                \n",
    "            distance.sort(key=lambda x: x[1])\n",
    "            distance = distance[:self.k]\n",
    "\n",
    "            # Add weights depending on distance-rank (harmonic row)\n",
    "            harmonic_row = [float(1)/float(i+1) for i in range(self.k)]            \n",
    "            for i in range(self.k):                \n",
    "                distance[i][3] = sum(harmonic_row[i:]) / self.k                           \n",
    "                \n",
    "\n",
    "            if self.distance_metric == 'uniform':                \n",
    "                occurences = np.bincount(np.array(distance)[:,2].astype(int))\n",
    "                y_pred.append(np.argmax(occurences))\n",
    "            else :\n",
    "                # Determine label by adding weights of each label\n",
    "                labels = np.unique(np.array(distance)[:,2].astype(int))\n",
    "                weights = []                \n",
    "                for lb in labels: \n",
    "                    weight = 0                                      \n",
    "                    for i in range(self.k):\n",
    "                        if (distance[i][2] == lb): weight = weight + distance[i][3] \n",
    "                    weights.append(weight)                \n",
    "                y_pred.append(labels[np.argmax(weights)])              \n",
    "        \n",
    "        return np.array(y_pred)        \n",
    "\n",
    "    \n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\"\n",
    "    Given vectors x1 and x2 with shape (n,) returns distance between vectors as float.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((x1 - x2)*(x1 - x2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Evaluation\n",
    "\n",
    "1) Implement functions to compute precision, recall and F1-score. `y_pred` and `y_true` are the vectors of predicted and true class labels respectively with shape `(n,)`, where `n` is the number of samples. Each function should return a float containing the corresponding score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "    pass\n",
    "\n",
    "def recall(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "    pass\n",
    "\n",
    "def f1score(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Evaluate the performance of kNN with uniform weighting on the Iris dataset for `k=1,3,5`. Train each of the `3` classifiers on the training data from Task 1. Perform the predictions on both the training and test data. Then compute precision, recall, and F1-score for each model and for both training and test data. Print all scores per model. What do you observe?\n",
    "\n",
    "**For all students other than B.Sc. Data Science:** \n",
    "Evaluate the kNN classifier with Euclidean distance-weighting. Compare the performance to uniform-weighting. How does the performance change compared to uniform weighting for each `k`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> *Write your observations here and report your results.* (double klick here to edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Explain why kNN with `k=1` achieves perfect results on the training data. Why is it not the best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> *Write your response here.* (double klick here to edit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.17 64-bit",
   "language": "python",
   "name": "python271764bit9edbe0919cd64f96ba45aec4dc2475c6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.17-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}